{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366f165f",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310d993",
   "metadata": {},
   "source": [
    "In this research project, we are going to analyze the credit card transactions data and build a model to predict fraud transacations. It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c47baf5",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fc780",
   "metadata": {},
   "source": [
    "The dataset contains transactions made by credit cards in September 2023 by American cardholders.\n",
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
    "\n",
    "- Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. \n",
    "- Feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning.\n",
    "- Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "The dataset has been broken down into multiple parts, since the volume is huge. The Part 1 can be accessed using the link below\n",
    "\n",
    "Link (Part1) : https://raw.githubusercontent.com/thendralvanans/Thinkful-Project/main/Capstone%204/Capstone_IV_Creditcard_Transactions_Part1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a580c8",
   "metadata": {},
   "source": [
    "# Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d63525",
   "metadata": {},
   "source": [
    "The Dataset is highly imbalanced, where one target class represents a significant proportion of observations than the other.\n",
    "\n",
    "There are several approaches to solving class imbalance problem before starting classification, such as:\n",
    "\n",
    "- More samples from the minority class(es) should be acquired from the knowledge domain.\n",
    "\n",
    "- Changing the loss function to give the failing minority class a higher cost.\n",
    "\n",
    "- Oversampling the minority class.\n",
    "\n",
    "- Undersampling the majority class.\n",
    "\n",
    "- Any combination of previous approaches.\n",
    "\n",
    "The best approach will be used to solve the class imbalance problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bd3cb",
   "metadata": {},
   "source": [
    "# Techniques and Specialization Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97a691",
   "metadata": {},
   "source": [
    "We will use various predictive models to see how accurate they are in detecting whether a transaction is a normal payment or a fraud. As described in the dataset, the features are scaled and the names of the features are not shown due to privacy reasons. Nevertheless, we can still analyze some important aspects of the dataset.\n",
    "\n",
    "- Understand the distribution of the data and perform exploratory data analysis\n",
    "- Preprocessing the data - Scaling, Distributing and Splitting the Data\n",
    "- Anomaly Detection and clean the data\n",
    "- Dimensionality Reduction and Clustering (t-SNE)\n",
    "- Handle the imbalance in the datasets using UnderSampling and Oversampling techniques\n",
    "- Oversampling with SMOTE\n",
    "- Create a 50/50 sub-dataframe ratio of \"Fraud\" and \"Non-Fraud\" transactions.\n",
    "- Determine the Classifiers we are going to use and decide which one has a higher accuracy.\n",
    "- Create a **Neural Network** and compare the accuracy to our best classifier.\n",
    "- Create a **Neural Network** and compare the accuracy between Undersampling vs Oversampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23554057",
   "metadata": {},
   "source": [
    "# Product Audience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d45a6",
   "metadata": {},
   "source": [
    "The Credit card fraud have been increasing day by day and the credit card companies are struggling to handle this problem. The product which we plan to build can act as a robust solution which can detect the fraudulent transactions. It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase. This product can be integrated with their respective applications which help to identify the fraud transactions in advance before the customers complaint which can makes the customers happy and makes the companies to achieve their business objective easier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
